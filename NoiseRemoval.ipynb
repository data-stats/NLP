{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Consider the below string\n",
    "str1 = \"This string will have lots of noise. We need to remove numbers like 12345 and the punctuation marks like ',',':',\"''\".\"\". Let's start noise removal concept in NLP.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This string will have lots of noise. We need to remove numbers like  and the punctuation marks like ',',':',.. Let's start noise removal concept in NLP.\""
      ]
     },
     "execution_count": 3,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will use pythons 're' library to do noise removal.\n",
    "import re\n",
    "re.sub(\"\\d\",\"\",str1) # This expression will remove all decimal values from the input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'string', 'will', 'have', 'lots', 'of', 'noise', '.', 'We', 'need', 'to', 'remove', 'numbers', 'like', '12345', 'and', 'the', 'punctuation', 'marks', 'like', \"'\", ',', \"'\", ',', \"'\", ':', \"'\", ',', '..', 'Let', \"'s\", 'start', 'noise', 'removal', 'concept', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "#Below example will remove punctuation marks from input string. For this, we will use library 'String'.\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words = word_tokenize(str1)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This string will have lots of noise We need to remove numbers like 12345 and the punctuation marks like .. Let 's start noise removal concept in NLP\n"
     ]
    }
   ],
   "source": [
    "str_without_punctuation = [w for w in words if w.lower()  not in string.punctuation]\n",
    "print(\" \".join(str_without_punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Getting all punctuation symbols\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'string', 'will', 'have', 'lots', 'of', 'noise', 'We', 'need', 'to', 'remove', 'numbers', 'like', '12345', 'and', 'the', 'punctuation', 'marks', 'like', 'Let', 's', 'start', 'noise', 'removal', 'concept', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "#regexp_tokenize is same as python's re module but the order of parameters is different.\n",
    "from nltk.tokenize import regexp_tokenize,wordpunct_tokenize,blankline_tokenize\n",
    "print(regexp_tokenize(str1,'\\w+')) # tokenizing the  input string into words.Symbol '+' represents more tham one times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12345']\n"
     ]
    }
   ],
   "source": [
    "print(regexp_tokenize(str1,'\\d+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', '. ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \" ',',':',.. \", \"'\", ' ', ' ', ' ', ' ', ' ', ' ', '.']\n"
     ]
    }
   ],
   "source": [
    "print(regexp_tokenize(str1,'\\W+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "str2 = \"This year's revenue is $34566 billion.\\n\\nLet's see the results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'year', 's', 'revenue', 'is', '34566', 'billion', 'Let', 's', 'see', 'the', 'results']\n"
     ]
    }
   ],
   "source": [
    "print(regexp_tokenize(str2,'\\w+')) #Notice that $ is not present in output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'year', 's', 'revenue', 'is', '$', '34566', 'billion', 'Let', 's', 'see', 'the', 'results']\n"
     ]
    }
   ],
   "source": [
    "print(regexp_tokenize(str2,'\\w+|\\$'))  #Notice that $ is present in output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'year', 's', 'revenue', 'is', '$34566', 'billion', 'Let', 's', 'see', 'the', 'results']\n"
     ]
    }
   ],
   "source": [
    "print(regexp_tokenize(str2,'\\w+|\\$[\\d]+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'year', \"'\", 's', 'revenue', 'is', '$', '34566', 'billion', '.', 'Let', \"'\", 's', 'see', 'the', 'results', '.']\n"
     ]
    }
   ],
   "source": [
    "print(wordpunct_tokenize(str2)) # It will tokenize the punctuation marks and words whereas the word_tokenize() tokenizes the words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'year', \"'s\", 'revenue', 'is', '$', '34566', 'billion', '.', 'Let', \"'s\", 'see', 'the', 'results', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(str2)) #Please observe the difference from previous output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This year's revenue is $34566 billion.\", \"Let's see the results.\"]\n"
     ]
    }
   ],
   "source": [
    "print(blankline_tokenize(str2)) #tokenizes the lines. Here it has divide input string into 2 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}